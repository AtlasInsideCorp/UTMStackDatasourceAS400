# UTMStack Datasource for AS400
## Description
UTMStack Datasource for AS400 is a tool developed in Java (using JDK 11), to interact with IBM i Systems.
The main function is to extract logs from IBM i System and send them to syslog server.

## Usage
In order to extract logs using this tool, you must configure some environment variables 

- _SYSLOG_PROTOCOL_: Represents the protocol of the listening syslog server to send logs to. Example: `udp`.
- _SYSLOG_HOST_: Represents the IP or HOST of the listening syslog server to send logs to. Example: `172.20.0.18`.
- _SYSLOG_PORT_: Represents the port of the listening syslog server to send logs to. Example: `514`.

### Configuration file of as400 servers
In order to the application know, from which AS400 servers had to extract the logs, you must create a file called
`Servers.json` under the `local_storage` folder. The `local_storage` folder
must be in the same folder where the executable .jar is.

If you are using docker, the Servers.json file must be inside the folder mapped to the volume.

**Note:** If you have more than one configuration file under `local_storage` folder, the last modified by date, will be taken,
but, we recommend that you have only one configuration file to avoid configuration issues.

#### Structure of Servers.json
The `Servers.json` file holds all servers of type AS400, that you need to extract logs from, and must have
th following structure:

~~~
{
    "serversAS400": [
        {
            "hostname": "your IBM system DNS Example: PUB400.COM",
            "userId": "User to access to your IBM system",
            "user_password": "Password of the user above",
            "tenant": "Unique server identifier string, Example: Server1"
        },
        {
            "hostname": "TEST.COM",
            "userId": "yourUser",
            "user_password": "pass",
            "tenant": "Server2"
        }
    ]
}
~~~
`serverId` is an Integer value of your choice, but must be unique for each server.

### With docker
To execute the tool with docker, you must create a docker container using this docker image `docker pull ghcr.io/atlasinsidecorp/as400jds:prod_${time_mark}`, 
with the environment variables configured as described before.
Example of code before, with ${time_mark} set:
`docker pull ghcr.io/atlasinsidecorp/as400jds:prod_20230120030016`. Contact to the repository administrator to get the latest version.
Also, to avoid processing the **same logs over and over again**, you must create a docker volume pointing to
`/local_storage/` folder with read and write permission.

To do that, create the folder on the machine to map the volume: `mkdir -p /utmstack/as400jds/`
Then, add the volume to docker compose config file, as follows:
~~~
...
volumes:
      - /utmstack/as400jds/:/local_storage
...
~~~
Start the docker compose.
If you aren't using compose create the volume with `docker volume create` command and associate it to the container before executing.

### With java
If you are using java directly, you need to have maven (3.8.6 at least) installed, then open a command prompt positioned in the project 
folder and execute one by one the following lines of code:
~~~
mvn clean
mvn -Pprod clean compile assembly:single
cd target
~~~
Then you must create a folder called `local_storage`, and inside put your [Servers.json](#configuration-file-of-as400-servers) file
Note that, the version (2.0.0) can change according to the POM version, check the 
pom.xml file to know current version.

After that, execute the following command using the command prompt:
~~~
java -jar as400-extractor-2.0.0-jar-with-dependencies.jar
~~~

## Begin to extract logs from an AS400 server from the scratch
Sometimes, after some executions, you realize that you need to start the log extraction from the beginning, to do that
you must know the meaning of the files generated inside the `local_storage` folder.

Each time that a server gets executed, it will generate a file inside the `local_storage` folder with the following structure:
`last_log_date_${serverAS400Instance.hostname}_${serverAS400Instance.serverId}.log` for example: `last_log_date_PUB400.COM_1.log`. This kind of file
will store the time mark of the last log processed in that server.

So, to begin the extraction from the first log, you only have to delete the file generated by the server where you need to restart the log extraction.

**IMPORTANT**
All the modifications in Server.json or any of the generated files or `local_storage` folder, must be done with the container stopped (using docker)
or the process stopped (direct with java). Also, we **strongly recommend** that you use as HOSTNAME _only letters, numbers, dot, hyphen and underscore._ 